I worked on multiple LangChain projects and learned the complete flow of building LLM-powered applications:

- I built a simple LangChain chatbot using GroqAI / Ollama and connected it with a custom Streamlit UI, where I learned how to send prompts, receive responses, and monitor executions using LangSmith.

- I learned how to build LangChain applications that work like APIs, and explored LangServe to deploy LangChain logic as easily accessible endpoints.

- I learned why RAG is important:
   - LLMs hallucinate when asked about
    topics after their training cutoff date.
   - LLMs cannot accurately answer     questions about private or proprietary company data.
    RAG solves this by injecting the exact relevant content into the model, ensuring accuracy and reducing hallucinations.

- I also implemented RAG using multiple external data sources like PDF, Wikipedia, ArXiv, and more.
For this, I explored LangChain Tools and Agents, which make it possible for LLMs to use external resources and perform actions dynamically.

To dive deeper, I regularly refer to the official LangChain documentation for Tools, Agents, RAG, and Deployment.
